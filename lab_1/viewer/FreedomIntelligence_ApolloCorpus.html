
		Multilingual Medicine: Model, Dataset, Benchmark, Code
	
Covering English, Chinese, French, Hindi, Spanish, Hindi, Arabic So far
   👨🏻‍💻Github •📃 Paper • 🌐 Demo • 🤗 ApolloCorpus • 🤗 XMedBench
  中文  |  English
		🌈 Update
	
[2024.03.07] Paper released.
[2024.02.12] ApolloCorpus and  XMedBench  is published！🎉
[2024.01.23] Apollo repo is published！🎉
		Results
	
 Apollo-0.5B • 🤗 Apollo-1.8B • 🤗 Apollo-2B  • 🤗 Apollo-6B • 🤗 Apollo-7B
Click to expand
 
		Data: Huge, Diverse, Clean, Multilingual
	
 
		Usage
	
Zip File
Data category
Pretrain:
json_name: {data_source}{language}{data_type}.json
data_type: medicalBook, medicalGuideline, medicalPaper, medicalWeb(from online forum), medicalWiki
language: en(English), zh(chinese), es(spanish), fr(french), hi(Hindi)
data_type: qa(generated qa from text)
data item:
data_type==text: list of string[
  "string1",
  "string2",
  ...
]
data_type==qa: list of qa pairs(list of string)[
  [
    "q1",
    "a1",
    "q2",
    "a2",
    ...
  ],
  ...
]
SFT:
json_name: {data_source}_{language}.json
data_type: code, general, math, medicalExam, medicalPatient
data item: list of qa pairs(list of string)  [
    [
      "q1",
      "a1",
      "q2",
      "a2",
      ...
    ],
    ...
  ]
		Citation
	
@misc{wang2024apollo,
   title={Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People},
   author={Xidong Wang and Nuo Chen and Junyin Chen and Yan Hu and Yidong Wang and Xiangbo Wu and Anningzhe Gao and Xiang Wan and Haizhou Li and Benyou Wang},
   year={2024},
   eprint={2403.03640},
   archivePrefix={arXiv},
   primaryClass={cs.CL}
}
