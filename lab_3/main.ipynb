{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T12:14:21.026953Z",
     "start_time": "2024-05-09T12:14:10.398521Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.optim import lr_scheduler\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from transformers import AutoModel\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbcd04cb8c56b4",
   "metadata": {},
   "source": [
    "检测当前设备，若显卡可用则设置device=cuda，否则设为cpu\n",
    "example用于决定读取数据的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2998eeba2f9fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T12:14:21.073030Z",
     "start_time": "2024-05-09T12:14:21.031618Z"
    }
   },
   "outputs": [],
   "source": [
    "def try_gpu(i=0):\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "device = try_gpu()\n",
    "example = False\n",
    "typ = torch.float32\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6026238764ad0c8",
   "metadata": {},
   "source": [
    "# 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9979456bb88776",
   "metadata": {},
   "source": [
    "## 设置标签"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b270cea7311341d",
   "metadata": {},
   "source": [
    "获取大小类，通过对网页的信息处理获得大小类标签相关信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3d737af4f3958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:49:23.356790Z",
     "start_time": "2024-05-09T09:49:23.273079Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(r'Hugging _dataset.html'):\n",
    "    with open(r'Hugging _dataset.html','r',encoding='utf-8') as f:\n",
    "        dataset_html = f.read()\n",
    "else:\n",
    "    dataset_web_respond = requests.get(url=r'https://huggingface.co/datasets',verify=False)\n",
    "    dataset_html = dataset_web_respond.text\n",
    "soup = bs(dataset_html,'html.parser')\n",
    "tags = soup.select('div.mb-20')[0].contents\n",
    "btags = []\n",
    "for i in tags:\n",
    "    try:\n",
    "        if 'mb-3' in i.get('class'):\n",
    "            btags.append(i)\n",
    "    except Exception:\n",
    "        pass\n",
    "cls = dict()\n",
    "scls = []\n",
    "for btag in btags:\n",
    "    blabel = btag.div.string.rstrip('\\t').rstrip('\\n')\n",
    "    temp = []\n",
    "    for a in btag.find_all('a'):\n",
    "        slabel = a.span.string\n",
    "        scls.append(slabel)\n",
    "        temp.append(slabel)\n",
    "    cls[blabel]=temp\n",
    "s_class_count = 0\n",
    "for k,v in cls.items():\n",
    "    s_class_count += len(v)\n",
    "    # print(k,v)\n",
    "print('小类总数',s_class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3280c1a6d0a3e17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:47:31.826620Z",
     "start_time": "2024-05-09T09:47:31.743557Z"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(r'Hugging _dataset.html'):\n",
    "    with open(r'Hugging _dataset.html','r',encoding='utf-8') as f:\n",
    "        dataset_html = f.read()\n",
    "else:\n",
    "    dataset_web_respond = requests.get(url=r'https://huggingface.co/datasets',verify=False)\n",
    "    dataset_html = dataset_web_respond.text\n",
    "soup = bs(dataset_html,'html.parser')\n",
    "tags = soup.select('div.mb-20')[0].contents\n",
    "btags = []\n",
    "for i in tags:\n",
    "    try:\n",
    "        if 'mb-3' in i.get('class'):\n",
    "            btags.append(i)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "bcls = []\n",
    "for btag in btags:\n",
    "    blabel = btag.div.string.rstrip('\\t').rstrip('\\n')\n",
    "    bcls.append(blabel)\n",
    "\n",
    "print(len(bcls))\n",
    "\n",
    "\n",
    "bc2h = dict()\n",
    "label = np.eye(7,7,dtype=np.float64)\n",
    "k = 0\n",
    "for v in bcls:\n",
    "        # print(v)\n",
    "    bc2h[v.replace(' ','_')] = label[k]\n",
    "    k += 1\n",
    "# c2h['Graph_Machine_Learning'].shape\n",
    "bc2h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5388846d22091e83",
   "metadata": {},
   "source": [
    "### one_hot编码\n",
    "发现小类一共46个，则可以用维度46的向量作为标签\n",
    "通过得到的映射关系构建c2h字典，将小类名映射到标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e70a91f67421a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:49:30.595158Z",
     "start_time": "2024-05-09T09:49:30.575908Z"
    }
   },
   "outputs": [],
   "source": [
    "c2h = dict()\n",
    "label = np.eye(46,46,dtype=np.float64)\n",
    "k = 0\n",
    "for _,v in cls.items():\n",
    "    for c in v :\n",
    "        # print(v)\n",
    "        c2h[c.replace(' ','_')] = label[k]\n",
    "        k += 1\n",
    "c2h['Graph_Machine_Learning'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d04cfc08f8f5b",
   "metadata": {},
   "source": [
    "获取数据，读取上次爬取到的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f79424e5bb006eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:52:40.940448Z",
     "start_time": "2024-05-09T09:52:39.946813Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data2.csv',sep='\\t')\n",
    "# if example:\n",
    "#     df = df[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4176af750eafd",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "- 空缺值处理\n",
    "- 文本向量化\n",
    "- dataframe格式变换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e00111e6cc06a",
   "metadata": {},
   "source": [
    "空缺值处理\n",
    "\n",
    "- 获取到的网页数据有部分缺失，使用-1替换\n",
    "- 对于数据简介，其中有许多无意义的换行符号，手动进行处理\n",
    "- 对于url,前面的https://huggingface.co/datasets/无意义，手动删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274dd53bfe22ab73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:52:49.860060Z",
     "start_time": "2024-05-09T09:52:49.552294Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[:,-1] = df.iloc[:,-1].apply(lambda x:x.replace('\\\\n','').replace('\\\\t',''))\n",
    "df.iloc[:,0] = df.iloc[:,0].apply(lambda x:x.replace('https://huggingface.co/datasets/',''))\n",
    "df.fillna(value=-1,inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96bc7cec8865fda",
   "metadata": {},
   "source": [
    "文本向量化\n",
    "\n",
    "\n",
    "借助网络上预处理好的模型将数据简介和数据名向量化，从而可以被处理\n",
    "\n",
    "\n",
    "选择的模型可以将文本转为512维的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f0b070d2fd89a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:47:45.423041Z",
     "start_time": "2024-05-09T09:47:44.696104Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_embeddings():\n",
    "        \"\"\"\n",
    "        文本转向量\n",
    "        \"\"\"\n",
    "        # 返回numpy数据\n",
    "        TextEmbedding_model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-small-en', trust_remote_code=True)\n",
    "        return TextEmbedding_model\n",
    "embedding_model = generate_embeddings()\n",
    "\n",
    "def m_embedding(text):\n",
    "    \"\"\"\n",
    "    文本转向量   \n",
    "    :param text: \n",
    "    :return: tensor\n",
    "    \"\"\"\n",
    "    embeddings = embedding_model.encode(text,max_length=3487)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48910908a0b98034",
   "metadata": {},
   "source": [
    "计算简介最大长度，作为参数传给编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55922617cb31bc9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:48:18.083318Z",
     "start_time": "2024-05-09T09:48:17.153952Z"
    }
   },
   "outputs": [],
   "source": [
    "m = 0\n",
    "for i in df.iloc[:,-1].to_list():\n",
    "    l = i.split().__len__()\n",
    "    m = max(m,l)\n",
    "print('max_length',m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df1459c475e0e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:53:28.082307Z",
     "start_time": "2024-05-09T09:53:28.071852Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec3509eb541572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据简介和数据名进行编码\n",
    "x_encode = df.iloc[:,[0,-1]].applymap(lambda x:m_embedding(x) if type(x)==str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023d5c640d8b7d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:53:02.443189Z",
     "start_time": "2024-05-09T09:53:02.416090Z"
    }
   },
   "outputs": [],
   "source": [
    "# 转为numpy对象\n",
    "x = x_encode.to_numpy()\n",
    "x_ = []\n",
    "for i in range(x.shape[0]):\n",
    "    ls = []\n",
    "    x_.append(list(np.append(x[i][0],x[i][-1])))\n",
    "x = np.array(x_)\n",
    "x1 = x\n",
    "print(x1.shape,x1.dtype)\n",
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702942787f16096",
   "metadata": {},
   "source": [
    "处理下载次数等数据信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffef8269b023366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:53:50.888007Z",
     "start_time": "2024-05-09T09:53:50.858574Z"
    }
   },
   "outputs": [],
   "source": [
    "x_ = df.iloc[:,1:4]\n",
    "def f(x):\n",
    "    try:\n",
    "        x = float(x)\n",
    "    except Exception:\n",
    "        x = -1\n",
    "    return x\n",
    "    \n",
    "x2 = x_.applymap(f).fillna(value=-1).to_numpy()\n",
    "print(x2.shape,x2.dtype)\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c49fbeaf049f1",
   "metadata": {},
   "source": [
    "合并文本编码后的数据\n",
    "\n",
    "\n",
    "长度为512*2+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1e75951353258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:53:48.087581Z",
     "start_time": "2024-05-09T09:53:48.050131Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.concatenate((x2,x1), axis=1)\n",
    "print(type(x),x.shape,x.dtype)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dea0913810a40b",
   "metadata": {},
   "source": [
    "制作标签\n",
    "\n",
    "使用之前得到的c2h小类转为one_hot编码\n",
    "\n",
    "最终得到46维向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc405e5438cb95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:42:16.125649Z",
     "start_time": "2024-05-09T09:42:16.089509Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db004d1853cd7734",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:55:45.139012Z",
     "start_time": "2024-05-09T09:55:35.716698Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3521e1e007ca1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:57:07.672108Z",
     "start_time": "2024-05-09T09:57:07.658107Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5db86e3d7d843d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:43:04.327867Z",
     "start_time": "2024-05-09T09:43:04.304923Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df.loc[:,'sclass'].apply(lambda x:np.array(c2h[x]))\n",
    "\n",
    "y = np.vstack(y)\n",
    "print(type(y),y.shape,y.dtype)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f54f232811b0",
   "metadata": {},
   "source": [
    "处理缺失值\n",
    "\n",
    "由于部分数据集没有相关数据，所以用0代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49238be636932896",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T07:03:03.284786Z",
     "start_time": "2024-05-09T07:03:03.259770Z"
    }
   },
   "outputs": [],
   "source": [
    "x[:,:3][x[:,:3] == -1] = np.nan\n",
    "x[:,:3][x[:,:3] == 0] = np.nan\n",
    "\n",
    "x = pd.DataFrame(x)\n",
    "# xx == np.nan\n",
    "x = pd.concat([x.iloc[:,:3].isna().astype(float),x.fillna(-1)],axis=1)\n",
    "x[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661dbc8376f2fb2",
   "metadata": {},
   "source": [
    "格式转换，将数据转为可以用于训练的格式并存储起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85884fe572543bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:54:32.551225Z",
     "start_time": "2024-05-09T09:54:32.529565Z"
    }
   },
   "outputs": [],
   "source": [
    "by.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce37760571a6ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:43:45.835070Z",
     "start_time": "2024-05-09T09:43:45.795055Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)\n",
    "by = torch.from_numpy(by)\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "by = by.to(device)\n",
    "torch.save((x,y,by),'bdata.data')\n",
    "x.shape,y.shape,x.dtype,y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7e0f0edf43f4ce",
   "metadata": {},
   "source": [
    "由于发现直接编码后的数据用来训练网络效果很差，所以继续将46个小类标签也编码，随后计算他们相关度，将512*2维转为46*2维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335e994a6bcd984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = pd.DataFrame(x)\n",
    "y = pd.DataFrame(y)\n",
    "by = pd.DataFrame(by)\n",
    "n = pd.concat([x,y,by],axis=1)\n",
    "non_duplicate_indices = n.iloc[:, :1030].drop_duplicates().index\n",
    "\n",
    "n = n.loc[non_duplicate_indices]\n",
    "x = torch.Tensor(n.iloc[:,:1030].values)\n",
    "y = torch.Tensor(n.iloc[:,1030:1030+46].values)\n",
    "by = torch.Tensor(n.iloc[:,1030+46:].values)\n",
    "\n",
    "\n",
    "# 计算相关性的函数\n",
    "cosine_fn = util.cos_sim\n",
    "\n",
    "# 记录最后的相关度\n",
    "df = pd.DataFrame(np.zeros([15347, 2*46]))\n",
    "\n",
    "# 小类到编码的映射\n",
    "s2e = dict()\n",
    "for k,v in cls.items():\n",
    "    s_class_count += len(v)\n",
    "    for s in v:\n",
    "        lab = m_embedding(k+s)\n",
    "        s2e[s] = lab\n",
    "        \n",
    "# 计算相关度\n",
    "for i in range(15347):\n",
    "    for j,(k,v) in enumerate(s2e.items()):\n",
    "        df.iloc[i,j] = cosine_fn(v,x[i,:512]).numpy()[0,0]\n",
    "        df.iloc[i,j+46] = cosine_fn(v,x[i,512:]).numpy()[0,0]\n",
    "\n",
    "\n",
    "x = pd.DataFrame(x)\n",
    "df = pd.concat([x.iloc[:,:6],df],axis=1).shape\n",
    "\n",
    "my_array = np.array(df)\n",
    "my_tensor = torch.tensor(my_array)\n",
    "torch.save(my_tensor,'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17bcb2c5c13e7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:34.658530Z",
     "start_time": "2024-05-09T09:41:29.776248Z"
    }
   },
   "outputs": [],
   "source": [
    "x,y = torch.load('data.data')\n",
    "pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d402f6f3900c7f",
   "metadata": {},
   "source": [
    "# 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da58aaee2723591c",
   "metadata": {},
   "source": [
    "数据装载和训练函数\n",
    "\n",
    "数据装载函数可以返回训练集和测试集\n",
    "\n",
    "训练函数中添加了保存模型和可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b4b3fbb92de70d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:44:54.588329Z",
     "start_time": "2024-05-09T09:44:54.570270Z"
    }
   },
   "outputs": [],
   "source": [
    "by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072b0404e58101d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T02:30:31.488870Z",
     "start_time": "2024-05-09T02:30:31.463111Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据装载\n",
    "def load_array(data_array,batch_size):\n",
    "    \"\"\"\n",
    "    分割数据集\n",
    "    \"\"\"\n",
    "    dataset = data.TensorDataset(*data_array)\n",
    "    # 30%作为验证集\n",
    "    val_size = int(len(dataset) * 0.3)  \n",
    "    train_size = len(dataset) - val_size\n",
    "    # 随机产生训练集和测试集\n",
    "    train_dataset, val_dataset = data.random_split(dataset, [train_size, val_size])\n",
    "    # 迭代器\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader,val_loader\n",
    "\n",
    "\n",
    "def train(data_loader,lr,net,epochs,optimizer=None,scheduler=None,device=device,flag='no_name'):\n",
    "    # 记录最好的准确率\n",
    "    best_val_acc = -1\n",
    "    # 加载数据\n",
    "    (train_loader,val_loader) = data_loader\n",
    "    # 模型位置调整\n",
    "    m_net = net.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss_fn.to(device)\n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.Adam(net.parameters(),lr=lr,weight_decay=1e-4)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer,step_size=300,gamma=0.9)\n",
    "\n",
    "    train_loss,train_acc,valid_acc = [],[],[]\n",
    "    no_increase = 0\n",
    "    for epoch in range(epochs):\n",
    "        # 训练\n",
    "        net.train()\n",
    "        train_epoch_loss,train_epoch_acc,valid_epoch_acc = 0,0,0\n",
    "        data_count = 0\n",
    "        for i,(xx,yy) in enumerate(train_loader):\n",
    "            # 前向传播\n",
    "            y_het = m_net(xx)\n",
    "            # 交叉熵损失\n",
    "            l =  loss_fn(y_het,yy)\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 反向传播\n",
    "            l.backward()\n",
    "            train_loss.append(l)\n",
    "            optimizer.step()\n",
    "            data_count += int(xx.shape[0])\n",
    "            train_epoch_loss += l.data\n",
    "            a = int(torch.sum(torch.argmax(y_het, axis=1) == torch.argmax(yy, axis=1)))\n",
    "            train_epoch_acc += a\n",
    "        # 记录训练的损失值和准确率\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        train_acc.append(train_epoch_acc / data_count)\n",
    "        # 测试\n",
    "        net.eval()\n",
    "        data_count = 0\n",
    "        for i,(xx,yy) in enumerate(val_loader):\n",
    "            y_het = m_net(xx)\n",
    "            data_count += int(xx.shape[0])\n",
    "            a = int(torch.sum(torch.argmax(y_het, axis=1) == torch.argmax(yy, axis=1)))\n",
    "            valid_epoch_acc += a\n",
    "        # 测试准确率    \n",
    "        valid_acc.append(valid_epoch_acc / data_count)\n",
    "        if valid_acc[-1] > best_val_acc:\n",
    "            # 保存最好的模型\n",
    "            no_increase = 0\n",
    "            best_val_acc = valid_acc[-1]\n",
    "            torch.save(m_net.state_dict(),flag + 'best_model.pkl')\n",
    "            print(f'---best_model_release  epoch {epoch + 1},train_loss {train_loss[-1]:.3f},train_acc {train_acc[-1]:.3f},valid_acc {valid_acc[-1]:.3f}')\n",
    "        elif best_val_acc - valid_acc[-1] > 0.2:\n",
    "            # 如果模型过差，则可以重新加载最好的模型再次开始\n",
    "            m_net = torch.load(flag + 'best_model.pkl')\n",
    "            no_increase += 1\n",
    "            print('!!!train_fail,reload_model,T_T')\n",
    "        else:\n",
    "            no_increase += 1\n",
    "        if no_increase == 1000:\n",
    "            # 长时间没有提升\n",
    "            return \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'  epoch {epoch + 1},train_loss {train_loss[-1]:.3f},train_acc {train_acc[-1]:.3f},valid_acc {valid_acc[-1]:.3f}')\n",
    "\n",
    "    # 学习率优化\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977cabb0d63d0f51",
   "metadata": {},
   "source": [
    "## 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624059629ab3129b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T12:14:54.550063Z",
     "start_time": "2024-05-09T12:14:54.529223Z"
    }
   },
   "outputs": [],
   "source": [
    "# 组件1\n",
    "\n",
    "def sblock(input_size,ouput_size):\n",
    "    \"1个全连接层\"\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm1d(input_size),\n",
    "#         nn.Dropout(0.1),\n",
    "        nn.Linear(input_size,ouput_size),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "# 组件2\n",
    "class inception(nn.Module):\n",
    "    \"\"\"\n",
    "    并行网络\n",
    "    \"\"\"\n",
    "    def __init__(self,in_size,c1_size,c2_size,c3_size,c4_size,**kwargs):\n",
    "        super(inception,self).__init__(**kwargs)\n",
    "        self.l1 = sblock(in_size,c1_size)\n",
    "        self.l2 = sblock(in_size,c2_size)\n",
    "        self.l3 = sblock(in_size,c3_size)\n",
    "        self.l4 = sblock(in_size,c4_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return torch.cat((self.l1(x),self.l2(x),self.l3(x),self.l4(x)),dim=1)\n",
    "\n",
    "# 组件3\n",
    "class inception_re(nn.Module):\n",
    "    \"\"\"\n",
    "    并行网络\n",
    "    \"\"\"\n",
    "    def __init__(self,c1_size,c2_size,c3_size,out1_size,out2_size,out3_size,**kwargs):\n",
    "        super(inception_re,self).__init__(**kwargs)\n",
    "        self.c1 = c1_size\n",
    "        self.c2 = c2_size + c1_size \n",
    "        self.c3 = c3_size + c2_size\n",
    "\n",
    "        self.l1 = sblock(c1_size,out1_size)\n",
    "        self.l2 = sblock(c2_size,out2_size)\n",
    "        self.l3 = sblock(c3_size,out3_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return torch.cat(\n",
    "            (\n",
    "                self.l1(x[:,:self.c1]),\n",
    "                self.l2(x[:,self.c1:self.c2]),\n",
    "                self.l3(x[:,self.c2:])\n",
    "            ),dim=1)\n",
    "\n",
    "    \n",
    "# 初始化参数\n",
    "def init_xavier(m):\n",
    "    \"\"\"\n",
    "    xavier初始化可以避免梯度爆炸、梯度消失\n",
    "    :param m: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0db3b7483dea83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:10:30.499434Z",
     "start_time": "2024-05-09T08:10:30.483419Z"
    }
   },
   "outputs": [],
   "source": [
    "# 瞎写的\n",
    "class Go_net(nn.Module):\n",
    "    \"\"\"\n",
    "    训练用网络\n",
    "    \"\"\"\n",
    "    def __init__(self,input_size=98):\n",
    "        \"\"\"\n",
    "        全连接+(并行+全连接)*n+全连接\n",
    "        :param input_size: \n",
    "        :param output_size: 最后分类个数\n",
    "        \"\"\"\n",
    "        super(Go_net,self).__init__()\n",
    "        self.inception_re1 = inception_re(6,46,46,8,124,124)\n",
    "\n",
    "        # self.sblock1 = sblock(input_size,128)\n",
    "        \n",
    "        \n",
    "        # self.sblock2 = sblock(1024,1024)\n",
    "        self.inception1 = inception(256,256,256,256,256)\n",
    "\n",
    "        # self.sblock3 = sblock(2048,1024)\n",
    "        # self.inception2 = inception(1024,64,64,128,256)\n",
    "        \n",
    "        self.sblock5 = sblock(1024,128)\n",
    "        # self.inception3 = inception(256,32,32,64,128)\n",
    "\n",
    "        self.sblock7 = sblock(128,46)   \n",
    "        \n",
    "        self.sequential = nn.Sequential(\n",
    "            # self.inception_re1,\n",
    "            # self.sblock1,\n",
    "            self.inception_re1,\n",
    "            self.inception1,\n",
    "            # self.sblock2,\n",
    "            # self.sblock3,\n",
    "            # self.inception2,\n",
    "            # self.sblock4,\n",
    "            self.sblock5,\n",
    "            # self.inception3,\n",
    "            # self.sblock6,\n",
    "            self.sblock7\n",
    "        )  \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param X: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "#         x = self.sblock1(x)\n",
    "#         x = self.sblock2(x)\n",
    "#         x = self.inception1(x)\n",
    "# #         x = self.sblock3(x)\n",
    "# #         x = self.inception2(x)\n",
    "#         x = self.sblock4(x)\n",
    "#         x = self.sblock5(x)  \n",
    "#         return x\n",
    "        return self.sequential(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16bac7b8b125f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数及网络初始化\n",
    "batch_size = 1024\n",
    "lr = 0.0001\n",
    "epoch = 20000\n",
    "m_Go_net = Go_net().to(torch.float32).to(device)\n",
    "\n",
    "m_net = m_Go_net\n",
    "m_net_name = 'm_Go_net'\n",
    "m_net.apply(init_xavier)\n",
    "\n",
    "x = x.to(torch.float32).to(device)\n",
    "y = y.to(torch.float32).to(device)\n",
    "m_net.to(device)\n",
    "dataset = load_array((x,y),batch_size)\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(m_net.parameters(),lr=lr,weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer,step_size=100,gamma=0.9)\n",
    "\n",
    "# 训练\n",
    "ok_model = train(data_loader=dataset,lr=lr,net=m_net,epochs=epoch,optimizer=optimizer,scheduler=scheduler,device=device,flag=m_net_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c9e3be88300a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:44:38.863233Z",
     "start_time": "2024-05-09T08:44:38.858192Z"
    }
   },
   "outputs": [],
   "source": [
    "c2i = dict()\n",
    "for k,v in c2h.items():\n",
    "    for kk,vv in cls.items():\n",
    "        kkk = k.replace('_',' ')\n",
    "        if kkk in vv:\n",
    "            c2i[v.argmax()] = kk + ' ' + k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a060c140fdc575c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T08:49:01.565336Z",
     "start_time": "2024-05-09T08:48:40.244662Z"
    }
   },
   "outputs": [],
   "source": [
    "# 小类检测\n",
    "m_Go_net_test = Go_net()\n",
    "m_Go_net_test.load_state_dict(torch.load('go_re/m_Go_netbest_model.pkl',map_location=device))\n",
    "m_Go_net_test.to(torch.bfloat16).to(device)\n",
    "\n",
    "val_data,val_label = torch.load('data.data')\n",
    "\n",
    "dataset = data.TensorDataset(val_data,val_label)\n",
    "val_loader = data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "def test(data):\n",
    "    with torch.no_grad():\n",
    "        m_Go_net_test.eval()\n",
    "        # 确保数据转换为BFloat16\n",
    "        data = data.to(torch.bfloat16)\n",
    "        return m_Go_net_test(data)\n",
    "    \n",
    "\n",
    "t = 0\n",
    "acc = 0\n",
    "for x,y in val_loader:\n",
    "    t+=1\n",
    "    if c2i[int(test(x).argmax(1))] == c2i[int(y.argmax(1))]:\n",
    "        acc += 1\n",
    "print(acc/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227b7552365a488",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T12:16:45.680554Z",
     "start_time": "2024-05-09T12:16:25.843996Z"
    }
   },
   "outputs": [],
   "source": [
    "class Go_net(nn.Module):\n",
    "    \"\"\"\n",
    "    训练用网络\n",
    "    \"\"\"\n",
    "    def __init__(self,input_size=98):\n",
    "        \"\"\"\n",
    "        全连接+(并行+全连接)*n+全连接\n",
    "        :param input_size: \n",
    "        :param output_size: 最后分类个数\n",
    "        \"\"\"\n",
    "        super(Go_net,self).__init__()\n",
    "#         self.inception_re1 = inception_re(6,46,46,8,60,60)\n",
    "\n",
    "        # self.sblock1 = sblock(input_size,128)\n",
    "        \n",
    "        \n",
    "        # self.sblock2 = sblock(1024,1024)\n",
    "        self.inception1 = inception(input_size,128,128,128,128)\n",
    "\n",
    "        # self.sblock3 = sblock(2048,1024)\n",
    "        # self.inception2 = inception(1024,64,64,128,256)\n",
    "        \n",
    "        self.sblock5 = sblock(512,256)\n",
    "        # self.inception3 = inception(256,32,32,64,128)\n",
    "\n",
    "        self.sblock7 = sblock(256,7)   \n",
    "        \n",
    "        self.sequential = nn.Sequential(\n",
    "            # self.inception_re1,\n",
    "            # self.sblock1,\n",
    "#             self.inception_re1,\n",
    "            self.inception1,\n",
    "            # self.sblock2,\n",
    "            # self.sblock3,\n",
    "            # self.inception2,\n",
    "            # self.sblock4,\n",
    "            self.sblock5,\n",
    "            # self.inception3,\n",
    "            # self.sblock6,\n",
    "            self.sblock7\n",
    "        )  \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param X: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "#         x = self.sblock1(x)\n",
    "#         x = self.sblock2(x)\n",
    "#         x = self.inception1(x)\n",
    "# #         x = self.sblock3(x)\n",
    "# #         x = self.inception2(x)\n",
    "#         x = self.sblock4(x)\n",
    "#         x = self.sblock5(x)  \n",
    "#         return x\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "def sblock(input_size,ouput_size):\n",
    "    \"1个全连接层\"\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm1d(input_size),\n",
    "        nn.Dropout(0.4),\n",
    "        nn.Linear(input_size,ouput_size),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "\n",
    "m_Go_net_test = Go_net()\n",
    "m_Go_net_test.load_state_dict(torch.load('go_re_bc/m_Go_netbest_model.pkl',map_location=device))\n",
    "m_Go_net_test.to(torch.bfloat16).to(device)\n",
    "t = torch.load('bdatae')\n",
    "val_data,val_label = t[0],t[1]\n",
    "\n",
    "dataset = data.TensorDataset(val_data,val_label)\n",
    "val_loader = data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "def test(data):\n",
    "    with torch.no_grad():\n",
    "        m_Go_net_test.eval()\n",
    "        # 确保数据转换为BFloat16\n",
    "        data = data.to(torch.bfloat16)\n",
    "        return m_Go_net_test(data)\n",
    "    \n",
    "\n",
    "t = 0\n",
    "acc = 0\n",
    "for x,y in val_loader:\n",
    "    t+=1\n",
    "    if int(test(x).argmax(1)) == int(y.argmax(1)):\n",
    "        acc += 1\n",
    "print(acc/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67b86ad3c0a9d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:11:19.558386Z",
     "start_time": "2024-05-09T10:11:14.427199Z"
    }
   },
   "outputs": [],
   "source": [
    "x,y = torch.load('data.data')\n",
    "x = pd.DataFrame(x.data)\n",
    "y = pd.DataFrame(y.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5dbdbd3cc7e9c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:11:24.419722Z",
     "start_time": "2024-05-09T10:11:24.327897Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d096c2bcc3287c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:11:34.256251Z",
     "start_time": "2024-05-09T10:11:32.267071Z"
    }
   },
   "outputs": [],
   "source": [
    "by = pd.concat(\n",
    "    [y.iloc[:,[0]].sum(axis=1),\n",
    "     y.iloc[:,1:18].sum(axis=1),\n",
    "     y.iloc[:,18:33].sum(axis=1),\n",
    "     y.iloc[:,33:39].sum(axis=1),\n",
    "     y.iloc[:,39:43].sum(axis=1),\n",
    "     y.iloc[:,43:45].sum(axis=1),\n",
    "     y.iloc[:,45:].sum(axis=1)\n",
    "     ],\n",
    "    axis=1)\n",
    "by\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526abd305ff5edd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:14:58.897240Z",
     "start_time": "2024-05-09T10:14:58.795119Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save([x,by],'bdatae')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635371262265d0b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:14:52.673233Z",
     "start_time": "2024-05-09T10:14:52.646241Z"
    }
   },
   "outputs": [],
   "source": [
    "# numpy_array = by.values\n",
    "# by = torch.tensor(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f7666094ccf4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:14:40.822830Z",
     "start_time": "2024-05-09T10:14:40.814139Z"
    }
   },
   "outputs": [],
   "source": [
    "by.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7bd736045f5443",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:14:48.821091Z",
     "start_time": "2024-05-09T10:14:48.705090Z"
    }
   },
   "outputs": [],
   "source": [
    "z = torch.load('bdatae.data')\n",
    "x,byy = z[0],z[1]\n",
    "x.shape,byy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568123c8237724f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:14:08.292653Z",
     "start_time": "2024-05-09T10:12:28.730843Z"
    }
   },
   "outputs": [],
   "source": [
    "# 支持向量机模型\n",
    "class svm_net(nn.Module):\n",
    "    def __init__(self,input_size=1030):\n",
    "        super(svm_net,self).__init__()\n",
    "        self.sblock1 = sblock(input_size,2048)\n",
    "        self.sblock2 = sblock(2048,512)\n",
    "        self.sblock4 = sblock(512,256)\n",
    "        self.sblock5 = sblock(256,7)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.sblock1(x)\n",
    "        x = self.sblock2(x)\n",
    "        # x = self.sblock3(x)\n",
    "        x = self.sblock4(x)\n",
    "        x = self.sblock5(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    # 参数及网络初始化\n",
    "batch_size = 2048\n",
    "lr = 0.01\n",
    "epoch = 20000\n",
    "m_Go_net = Go_net().to(torch.float32).to(device)\n",
    "\n",
    "m_svm_net = svm_net(98)\n",
    "\n",
    "m_net = m_svm_net\n",
    "m_net_name = 'm_svm_net'\n",
    "m_net.apply(init_xavier)\n",
    "# x,by = torch.load('bdata.data')\n",
    "x = x.to(torch.float32).to(device)\n",
    "by = by.to(torch.float32).to(device)\n",
    "m_net.to(device)\n",
    "dataset = load_array((x,by),batch_size)\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(m_net.parameters(),lr=lr,weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer,step_size=100,gamma=0.9)\n",
    "\n",
    "ok_model = train(data_loader=dataset,lr=lr,net=m_net,epochs=epoch,optimizer=optimizer,scheduler=scheduler,device=device,flag=m_net_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be221af9b15dea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:18:32.402710Z",
     "start_time": "2024-05-09T10:15:13.433096Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ok_model = train(data_loader=dataset,lr=lr,net=m_net,epochs=epoch,optimizer=optimizer,scheduler=scheduler,device=device,flag=m_net_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
